{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "slFepDbVEBAi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import pandas as pd\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Classification by Machine Learning Models."
      ],
      "metadata": {
        "id": "3Jp5RGlGG8y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and resize images from a folder\n",
        "def load_and_resize_images_from_folder(folder, target_size):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, target_size)\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# Specify your image folder and target size\n",
        "image_folder = '/content/drive/MyDrive/REX Technologies/img_align_celeba'\n",
        "target_size = (64, 64)\n",
        "\n",
        "# Load and resize images from the folder\n",
        "images = load_and_resize_images_from_folder(image_folder, target_size)\n",
        "\n",
        "# Flatten the images\n",
        "X = [img.flatten() for img in images]"
      ],
      "metadata": {
        "id": "fayaAN98GEQH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Label -1 for Female and 1 for male indication."
      ],
      "metadata": {
        "id": "e9g1V7OPHyob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = pd.read_csv(\"/content/drive/MyDrive/REX Technologies/list_attr_celeba.csv\")\n",
        "label = list(label['Male'])\n",
        "label = label[0:5000]\n",
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ape2ZEgKGD7Q",
        "outputId": "3a3c0a5f-9b80-4e70-8cb3-5ec4d67e29a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " -1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "17tR7AyMFr5D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as sm\n",
        "from sklearn.utils import all_estimators\n",
        "import pickle\n",
        "estimators = all_estimators(type_filter='classifier')\n",
        "model_name=[]\n",
        "model_precision=[]\n",
        "model_accuracy=[]\n",
        "model_training_time=[]\n",
        "model_path = \"/content/drive/MyDrive/REX Technologies/Model_save\"\n",
        "for name, get_model in estimators:\n",
        "    try:\n",
        "        model = get_model()\n",
        "        # Train the classifier and measure time\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train,y_train)\n",
        "        model_training_time.append(time.time() - start_time)\n",
        "        y_pred=model.predict(X_test)\n",
        "        model_precision.append(sm.precision_score(y_test, y_pred))\n",
        "        model_accuracy.append(sm.accuracy_score(y_test, y_pred))\n",
        "        model_name.append(name)\n",
        "        # Save model with pickle model\n",
        "        with open(model_path + f\"/{name}.pkl\",'wb') as model_file:\n",
        "            pickle.dump(model, model_file)\n",
        "    except Exception as e:\n",
        "        print('Unable to import', name)\n",
        "        print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKLTpft2Fs5V",
        "outputId": "2a291cba-9a89-446b-8302-043eb00508a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to import CategoricalNB\n",
            "Negative values in data passed to CategoricalNB (input X)\n",
            "Unable to import ClassifierChain\n",
            "_BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
            "Unable to import ComplementNB\n",
            "Negative values in data passed to ComplementNB (input X)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
            "  probabilities /= normalizer\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unable to import MultiOutputClassifier\n",
            "MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
            "Unable to import MultinomialNB\n",
            "Negative values in data passed to MultinomialNB (input X)\n",
            "Unable to import OneVsOneClassifier\n",
            "OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
            "Unable to import OneVsRestClassifier\n",
            "OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
            "Unable to import OutputCodeClassifier\n",
            "OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unable to import RadiusNeighborsClassifier\n",
            "No neighbors found for test samples array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
            "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
            "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
            "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
            "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
            "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
            "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
            "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
            "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
            "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
            "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
            "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
            "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
            "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
            "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
            "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
            "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
            "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
            "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
            "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
            "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
            "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
            "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
            "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
            "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
            "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
            "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
            "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
            "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
            "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
            "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
            "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
            "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
            "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
            "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
            "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
            "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
            "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
            "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
            "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
            "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
            "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
            "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
            "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
            "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
            "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
            "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
            "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
            "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
            "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
            "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
            "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
            "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
            "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
            "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
            "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
            "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
            "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
            "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
            "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
            "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
            "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
            "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
            "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
            "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
            "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
            "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
            "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
            "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
            "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
            "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
            "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
            "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
            "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
            "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
            "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
            "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
            "Unable to import StackingClassifier\n",
            "StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
            "Unable to import VotingClassifier\n",
            "VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results=pd.DataFrame({\"Model Name\":model_name, \"Model accuracy\":model_accuracy, \"Model precision\":model_precision})\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "UCj_st5qFtdC",
        "outputId": "92904fd9-7a8d-498c-bc90-1f01e2aa2218"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model Name  Model accuracy  Model precision\n",
              "0               AdaBoostClassifier           0.550         0.429553\n",
              "1                BaggingClassifier           0.566         0.441315\n",
              "2                      BernoulliNB           0.486         0.399618\n",
              "3           CalibratedClassifierCV           0.591         0.000000\n",
              "4           DecisionTreeClassifier           0.506         0.400000\n",
              "5                  DummyClassifier           0.591         0.000000\n",
              "6              ExtraTreeClassifier           0.505         0.399533\n",
              "7             ExtraTreesClassifier           0.573         0.428571\n",
              "8                       GaussianNB           0.493         0.405405\n",
              "9        GaussianProcessClassifier           0.591         0.000000\n",
              "10      GradientBoostingClassifier           0.559         0.394737\n",
              "11  HistGradientBoostingClassifier           0.546         0.400881\n",
              "12            KNeighborsClassifier           0.541         0.433862\n",
              "13                LabelPropagation           0.409         0.409000\n",
              "14                  LabelSpreading           0.409         0.409000\n",
              "15      LinearDiscriminantAnalysis           0.493         0.391111\n",
              "16                       LinearSVC           0.521         0.417453\n",
              "17              LogisticRegression           0.526         0.421308\n",
              "18            LogisticRegressionCV           0.572         0.405941\n",
              "19                   MLPClassifier           0.540         0.437037\n",
              "20                 NearestCentroid           0.481         0.396617\n",
              "21                           NuSVC           0.534         0.413897\n",
              "22     PassiveAggressiveClassifier           0.519         0.414692\n",
              "23                      Perceptron           0.518         0.412888\n",
              "24   QuadraticDiscriminantAnalysis           0.514         0.418259\n",
              "25          RandomForestClassifier           0.563         0.393939\n",
              "26                 RidgeClassifier           0.514         0.417910\n",
              "27               RidgeClassifierCV           0.507         0.408297\n",
              "28                   SGDClassifier           0.533         0.431280\n",
              "29                             SVC           0.594         0.542857"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f94f51db-3c26-43b3-8156-ad8e513c6dac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Model accuracy</th>\n",
              "      <th>Model precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.429553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BaggingClassifier</td>\n",
              "      <td>0.566</td>\n",
              "      <td>0.441315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>0.486</td>\n",
              "      <td>0.399618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CalibratedClassifierCV</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DummyClassifier</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ExtraTreeClassifier</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.399533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>0.493</td>\n",
              "      <td>0.405405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GaussianProcessClassifier</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.559</td>\n",
              "      <td>0.394737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>HistGradientBoostingClassifier</td>\n",
              "      <td>0.546</td>\n",
              "      <td>0.400881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.541</td>\n",
              "      <td>0.433862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LabelPropagation</td>\n",
              "      <td>0.409</td>\n",
              "      <td>0.409000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LabelSpreading</td>\n",
              "      <td>0.409</td>\n",
              "      <td>0.409000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>0.493</td>\n",
              "      <td>0.391111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>0.521</td>\n",
              "      <td>0.417453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.526</td>\n",
              "      <td>0.421308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>LogisticRegressionCV</td>\n",
              "      <td>0.572</td>\n",
              "      <td>0.405941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.437037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NearestCentroid</td>\n",
              "      <td>0.481</td>\n",
              "      <td>0.396617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NuSVC</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.413897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PassiveAggressiveClassifier</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.414692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.412888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.418259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.563</td>\n",
              "      <td>0.393939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.417910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>RidgeClassifierCV</td>\n",
              "      <td>0.507</td>\n",
              "      <td>0.408297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.431280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.594</td>\n",
              "      <td>0.542857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f94f51db-3c26-43b3-8156-ad8e513c6dac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f94f51db-3c26-43b3-8156-ad8e513c6dac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f94f51db-3c26-43b3-8156-ad8e513c6dac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01bb8e8d-83f6-4f55-b76e-803bfcca9608\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01bb8e8d-83f6-4f55-b76e-803bfcca9608')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01bb8e8d-83f6-4f55-b76e-803bfcca9608 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_training_time = model_training_time[0:30]\n",
        "results[\"training_time\"] = model_training_time\n",
        "results.to_csv('result.csv', index=False)"
      ],
      "metadata": {
        "id": "JDwLuMA7F2u0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "3S0ElhWPsYD6",
        "outputId": "1cab31d0-c4ea-4f85-eaaa-9a5ca5144af7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model Name  Model accuracy  Model precision  \\\n",
              "0               AdaBoostClassifier           0.550         0.429553   \n",
              "1                BaggingClassifier           0.566         0.441315   \n",
              "2                      BernoulliNB           0.486         0.399618   \n",
              "3           CalibratedClassifierCV           0.591         0.000000   \n",
              "4           DecisionTreeClassifier           0.506         0.400000   \n",
              "5                  DummyClassifier           0.591         0.000000   \n",
              "6              ExtraTreeClassifier           0.505         0.399533   \n",
              "7             ExtraTreesClassifier           0.573         0.428571   \n",
              "8                       GaussianNB           0.493         0.405405   \n",
              "9        GaussianProcessClassifier           0.591         0.000000   \n",
              "10      GradientBoostingClassifier           0.559         0.394737   \n",
              "11  HistGradientBoostingClassifier           0.546         0.400881   \n",
              "12            KNeighborsClassifier           0.541         0.433862   \n",
              "13                LabelPropagation           0.409         0.409000   \n",
              "14                  LabelSpreading           0.409         0.409000   \n",
              "15      LinearDiscriminantAnalysis           0.493         0.391111   \n",
              "16                       LinearSVC           0.521         0.417453   \n",
              "17              LogisticRegression           0.526         0.421308   \n",
              "18            LogisticRegressionCV           0.572         0.405941   \n",
              "19                   MLPClassifier           0.540         0.437037   \n",
              "20                 NearestCentroid           0.481         0.396617   \n",
              "21                           NuSVC           0.534         0.413897   \n",
              "22     PassiveAggressiveClassifier           0.519         0.414692   \n",
              "23                      Perceptron           0.518         0.412888   \n",
              "24   QuadraticDiscriminantAnalysis           0.514         0.418259   \n",
              "25          RandomForestClassifier           0.563         0.393939   \n",
              "26                 RidgeClassifier           0.514         0.417910   \n",
              "27               RidgeClassifierCV           0.507         0.408297   \n",
              "28                   SGDClassifier           0.533         0.431280   \n",
              "29                             SVC           0.594         0.542857   \n",
              "\n",
              "    training_time  \n",
              "0      226.543586  \n",
              "1      464.845762  \n",
              "2        0.907184  \n",
              "3      650.226175  \n",
              "4       76.956466  \n",
              "5        0.004359  \n",
              "6        0.308481  \n",
              "7       16.517782  \n",
              "8        1.015052  \n",
              "9      227.459330  \n",
              "10    1294.621638  \n",
              "11     294.035523  \n",
              "12       0.055232  \n",
              "13       7.818723  \n",
              "14       7.577719  \n",
              "15     128.555816  \n",
              "16     143.474696  \n",
              "17      14.237652  \n",
              "18     476.954894  \n",
              "19     186.997484  \n",
              "20       0.254919  \n",
              "21     225.242044  \n",
              "22      41.950603  \n",
              "23       9.607046  \n",
              "24      69.203346  \n",
              "25       0.052495  \n",
              "26      41.188475  \n",
              "27       8.572002  \n",
              "28      28.290312  \n",
              "29      13.571839  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f49a5c6-5295-46ad-ab54-755948cf25af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Model accuracy</th>\n",
              "      <th>Model precision</th>\n",
              "      <th>training_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.429553</td>\n",
              "      <td>226.543586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BaggingClassifier</td>\n",
              "      <td>0.566</td>\n",
              "      <td>0.441315</td>\n",
              "      <td>464.845762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>0.486</td>\n",
              "      <td>0.399618</td>\n",
              "      <td>0.907184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CalibratedClassifierCV</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>650.226175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>76.956466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DummyClassifier</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ExtraTreeClassifier</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.399533</td>\n",
              "      <td>0.308481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>16.517782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>0.493</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>1.015052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GaussianProcessClassifier</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>227.459330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.559</td>\n",
              "      <td>0.394737</td>\n",
              "      <td>1294.621638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>HistGradientBoostingClassifier</td>\n",
              "      <td>0.546</td>\n",
              "      <td>0.400881</td>\n",
              "      <td>294.035523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.541</td>\n",
              "      <td>0.433862</td>\n",
              "      <td>0.055232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LabelPropagation</td>\n",
              "      <td>0.409</td>\n",
              "      <td>0.409000</td>\n",
              "      <td>7.818723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LabelSpreading</td>\n",
              "      <td>0.409</td>\n",
              "      <td>0.409000</td>\n",
              "      <td>7.577719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>0.493</td>\n",
              "      <td>0.391111</td>\n",
              "      <td>128.555816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>0.521</td>\n",
              "      <td>0.417453</td>\n",
              "      <td>143.474696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.526</td>\n",
              "      <td>0.421308</td>\n",
              "      <td>14.237652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>LogisticRegressionCV</td>\n",
              "      <td>0.572</td>\n",
              "      <td>0.405941</td>\n",
              "      <td>476.954894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.437037</td>\n",
              "      <td>186.997484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NearestCentroid</td>\n",
              "      <td>0.481</td>\n",
              "      <td>0.396617</td>\n",
              "      <td>0.254919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NuSVC</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.413897</td>\n",
              "      <td>225.242044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PassiveAggressiveClassifier</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.414692</td>\n",
              "      <td>41.950603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.412888</td>\n",
              "      <td>9.607046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.418259</td>\n",
              "      <td>69.203346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.563</td>\n",
              "      <td>0.393939</td>\n",
              "      <td>0.052495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>41.188475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>RidgeClassifierCV</td>\n",
              "      <td>0.507</td>\n",
              "      <td>0.408297</td>\n",
              "      <td>8.572002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.431280</td>\n",
              "      <td>28.290312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.594</td>\n",
              "      <td>0.542857</td>\n",
              "      <td>13.571839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f49a5c6-5295-46ad-ab54-755948cf25af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f49a5c6-5295-46ad-ab54-755948cf25af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f49a5c6-5295-46ad-ab54-755948cf25af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd16ec30-e9af-448a-9c02-6bf9df310ad7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd16ec30-e9af-448a-9c02-6bf9df310ad7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd16ec30-e9af-448a-9c02-6bf9df310ad7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FdxCF3Q53SKV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}